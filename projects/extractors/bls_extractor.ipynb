{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from typing import List, Mapping, Tuple, Union\n",
    "\n",
    "# Set width of column for tables in polars\n",
    "pl.Config.set_fmt_str_lengths(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get All CES Series using Polars\n",
    "- Polars is used instead; Pandas library execution would take signifinicant longer time especially in the read operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "BLS_PATH_URL = \"https://download.bls.gov/pub/time.series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_response_from_url(url: str, headers: Mapping[str, str]) -> str:\n",
    "    response = httpx.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def build_url(id: str) -> str:\n",
    "    # The key to access metadata for ALL CES Series\n",
    "    key = \"ce.data.0.AllCESSeries\"\n",
    "    return f\"{BLS_PATH_URL}/{id}/{key}\"\n",
    "\n",
    "def parse_csv(obj: str) -> pl.DataFrame:\n",
    "    # Parsing CSV with pandas pd.read_csv takes longer time, using polars for faster read operation\n",
    "    data = pl.read_csv(io.StringIO(obj), separator=\"\\t\", infer_schema_length=False)\n",
    "    data.columns = [col.strip() for col in data.columns]\n",
    "    return data\n",
    "\n",
    "def map_ce_series_name(data: pl.DataFrame, series_id: str) -> pl.DataFrame:\n",
    "    # Get the ce series name mapping\n",
    "    obj = get_response_from_url(\n",
    "        f\"{BLS_PATH_URL}/{series_id}/ce.series\",\n",
    "        headers=HEADERS,\n",
    "    )\n",
    "    # Parse the series id to series name mapping\n",
    "    ce_series = (\n",
    "        parse_csv(obj)\n",
    "        .with_columns(pl.col(\"series_id\").str.strip())\n",
    "        .select([\"series_id\", \"series_title\"])\n",
    "    )\n",
    "    series_id_to_name = {}\n",
    "    for row in ce_series.iter_rows():\n",
    "        series_id_to_name[row[0]] = row[1]\n",
    "\n",
    "    data = (\n",
    "        data.with_columns(\n",
    "            pl.col(\"series_id\").map_dict(series_id_to_name).alias(\"series_name\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"series_name\")\n",
    "            .str.replace_all(\" \", \"_\")\n",
    "            .str.replace_all(\",\", \"\")\n",
    "            .str.replace_all(\"-\", \"_\")\n",
    "            .str.replace_all(\"not_seasonally_adjusted\", \"nsa\")\n",
    "            .str.replace_all(\"seasonally_adjusted\", \"sa\")\n",
    "            .str.to_lowercase()\n",
    "        )\n",
    "        .select(\n",
    "            pl.col(\"series_name\"),\n",
    "            pl.all().exclude([\"series_name\", \"series_id\"]),\n",
    "        )\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_all_series(series_id: str = \"ce\") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts time series data for the given series ID from US Labour of Statistics.\n",
    "\n",
    "    Parameters:\n",
    "        series_id (str): The series ID for which to extract time series data.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: A Polars DataFrame containing the extracted time series data.\n",
    "        \n",
    "    This function retrieves time series data for the specified series ID using the\n",
    "    `get_response_from_url()` function to fetch the data from a URL. The retrieved\n",
    "    data is then parsed into a Polars DataFrame using the `parse_csv()` function.\n",
    "    \n",
    "    The function proceeds to perform the following data transformations:\n",
    "    1. Removes rows with \"M13\" as the period.\n",
    "    2. Parses the \"year\" and \"period\" columns and creates a new \"time\" column with datetime format.\n",
    "    3. Selects the \"series_id\", \"time\", and \"value\" columns.\n",
    "    4. Shrinks the data types of columns to optimize memory usage.\n",
    "    \n",
    "    If the `series_id` is \"ce\", the function further processes the data using the\n",
    "    `map_ce_series_name()` function to map the series names based on the specified series ID.\n",
    "    \n",
    "    The resulting Polars DataFrame contains the extracted time series data ready for analysis.\n",
    "    \"\"\"\n",
    "    obj = get_response_from_url(\n",
    "        build_url(series_id),\n",
    "        headers=HEADERS,\n",
    "    )\n",
    "    raw_data = parse_csv(obj)\n",
    "    \n",
    "    data = (\n",
    "        raw_data\n",
    "        # Remove M13 as period\n",
    "        .filter(pl.col(\"period\") != \"M13\")\n",
    "        # Parse datetime col\n",
    "        .with_columns(\n",
    "            [\n",
    "                (pl.col(\"year\") + pl.col(\"period\"))\n",
    "                .alias(\"time\")\n",
    "                .str.to_datetime(\"%YM%m\", strict=False),\n",
    "            ]\n",
    "        )\n",
    "        .select(\n",
    "            [\n",
    "                pl.col(\"series_id\").str.strip(),\n",
    "                pl.col(\"time\"),\n",
    "                pl.col(\"value\").str.strip().cast(pl.Float64),\n",
    "            ]\n",
    "        )\n",
    "        .select(pl.all().shrink_dtype())\n",
    "    )\n",
    "\n",
    "    if series_id == \"ce\":\n",
    "        data = map_ce_series_name(data=data, series_id=series_id)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_data = extractor_all_series(\"ce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows for all CES Series: 7895859\n",
      "Snapshot of the data extracted: shape: (5, 3)\n",
      "┌──────────────────────────────────────────┬─────────────────────┬─────────┐\n",
      "│ series_name                              ┆ time                ┆ value   │\n",
      "│ ---                                      ┆ ---                 ┆ ---     │\n",
      "│ str                                      ┆ datetime[μs]        ┆ f32     │\n",
      "╞══════════════════════════════════════════╪═════════════════════╪═════════╡\n",
      "│ all_employees_thousands_total_nonfarm_sa ┆ 1939-01-01 00:00:00 ┆ 29923.0 │\n",
      "│ all_employees_thousands_total_nonfarm_sa ┆ 1939-02-01 00:00:00 ┆ 30100.0 │\n",
      "│ all_employees_thousands_total_nonfarm_sa ┆ 1939-03-01 00:00:00 ┆ 30280.0 │\n",
      "│ all_employees_thousands_total_nonfarm_sa ┆ 1939-04-01 00:00:00 ┆ 30094.0 │\n",
      "│ all_employees_thousands_total_nonfarm_sa ┆ 1939-05-01 00:00:00 ┆ 30299.0 │\n",
      "└──────────────────────────────────────────┴─────────────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows for all CES Series: {len(bls_data)}\")\n",
    "print(f\"Snapshot of the data extracted: {bls_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract one of the popular time series using CES Public Open API using Pandas\n",
    "- https://data.bls.gov/cgi-bin/surveymost?bls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def process_series_data(series):\n",
    "    data_rows = []\n",
    "    seriesId = series[\"seriesID\"]\n",
    "    for item in series[\"data\"]:\n",
    "        year = item[\"year\"]\n",
    "        period = item[\"period\"]\n",
    "        value = item[\"value\"]\n",
    "        footnotes = \"\"\n",
    "        for footnote in item[\"footnotes\"]:\n",
    "            if footnote:\n",
    "                footnotes = footnotes + footnote[\"text\"] + \",\"\n",
    "\n",
    "        if \"M01\" <= period <= \"M12\":\n",
    "            data_rows.append([seriesId, year, period, value, footnotes[0:-1]])\n",
    "\n",
    "    return data_rows\n",
    "\n",
    "def json_to_dataframe(json_data) -> pd.DataFrame:\n",
    "    data_rows = []\n",
    "    for series in json_data[\"Results\"][\"series\"]:\n",
    "        data_rows.extend(process_series_data(series))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data_rows, columns=[\"series id\", \"year\", \"period\", \"value\", \"footnotes\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_datetime(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"time\"] = pd.to_datetime(df[\"year\"] + \"-\" + df[\"period\"].str[-2:] + \"-01\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_snakecase(text) -> str:\n",
    "    return text.lower().replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "def remove_special_characters(text)-> str:\n",
    "    # Remove parentheses, hyphens, and square brackets\n",
    "    cleaned_text = re.sub(r\"[\\(\\)\\-\\[\\]]\", \"\", text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main extractor using v1 API \n",
    "def get_bls_series(series_id_to_name: Mapping[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves time series data for the specified series IDs from the BLS API.\n",
    "\n",
    "    Parameters:\n",
    "        series_id_to_name (Mapping[str, str]): A mapping of series IDs to their corresponding names.\n",
    "                                              The keys are series IDs (str), and the values are\n",
    "                                              the respective series names (str).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the extracted time series data.\n",
    "\n",
    "    This function uses the BLS API to fetch time series data for multiple series IDs based on the\n",
    "    provided mapping of series IDs to names. The function performs the following steps to obtain\n",
    "    and preprocess the data:\n",
    "\n",
    "    1. Prepares the request data as a JSON string with the specified series IDs, start year, and end year.\n",
    "    2. Sends a POST request to the BLS API to fetch the time series data in JSON format.\n",
    "    3. Converts the JSON data to a pandas DataFrame using the json_to_dataframe function.\n",
    "    4. Preprocesses the DataFrame by parsing the datetime, replacing series IDs with series names,\n",
    "       converting column names to snake_case, renaming the \"series_id\" column to \"series_name\",\n",
    "       converting series_name values to snakecase, and removing special characters.\n",
    "    5. Reshapes the DataFrame to keep only the desired columns (\"series_name\", \"time\", \"value\"),\n",
    "       and sets \"series_name\" as the index of the DataFrame.\n",
    "\n",
    "    The provided mapping series_id_to_name allows you to retrieve data for multiple series IDs\n",
    "    simultaneously. The resulting DataFrame contains the time series data ready for further analysis\n",
    "    or visualization.\n",
    "    \"\"\"\n",
    "    headers = {\"Content-type\": \"application/json\"}\n",
    "    # Prepare the request data as a JSON string\n",
    "    # NOTE: The start year and end year is set at 2013 and 2023 respectively\n",
    "    data = json.dumps(\n",
    "        {\"seriesid\": list(series_id_to_name.keys()), \"startyear\": \"2013\", \"endyear\": \"2023\"}\n",
    "    )\n",
    "    # Send a POST request to the BLS API to get the JSON data\n",
    "    p = requests.post(\n",
    "        \"https://api.bls.gov/publicAPI/v1/timeseries/data/\", data=data, headers=headers\n",
    "    )\n",
    "    # Load the json data\n",
    "    json_data = json.loads(p.text)\n",
    "    # Convert json_data to pd.DataFrame\n",
    "    df = json_to_dataframe(json_data)\n",
    "    \n",
    "    # Preprocessing data into desired format\n",
    "    data = (\n",
    "        # Parse datetime to YY-MM-DD format\n",
    "        parse_datetime(df)\n",
    "        # Replace series id with series name\n",
    "        .replace({\"series id\": series_id_to_name})\n",
    "        # Make all column name to snake_case\n",
    "        .rename(columns=lambda x: to_snakecase(x))\n",
    "        # Replace name for column \"series_id\" to \"series_name\"\n",
    "        .rename(columns={\"series_id\": \"series_name\"})\n",
    "        # Turn all values in series_name to snakecase and remove special characters\n",
    "        .assign(\n",
    "            series_id=lambda x: x[\"series_name\"]\n",
    "            .apply(to_snakecase)\n",
    "            .apply(remove_special_characters)\n",
    "        )\n",
    "        # Reshape df to desired features only\n",
    "        .pipe(lambda df: df.loc[:, [\"series_name\", \"time\", \"value\"]])\n",
    "        .set_index(\"series_name\")\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set series id and series name \n",
    "SERIES_ID_TO_NAME = {\"LNS14000000\": \"Unemployment Rate (Seasonally Adjusted)\"}\n",
    "# Extract time series using Public Data V1 API\n",
    "bls_series = get_bls_series(series_id_to_name=SERIES_ID_TO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows for time series since 2013: 120\n",
      "time     datetime64[ns]\n",
      "value            object\n",
      "dtype: object\n",
      "Snapshot of the data extracted:                                               time value\n",
      "series_name                                             \n",
      "Unemployment Rate (Seasonally Adjusted) 2022-12-01   3.5\n",
      "Unemployment Rate (Seasonally Adjusted) 2022-11-01   3.6\n",
      "Unemployment Rate (Seasonally Adjusted) 2022-10-01   3.7\n",
      "Unemployment Rate (Seasonally Adjusted) 2022-09-01   3.5\n",
      "Unemployment Rate (Seasonally Adjusted) 2022-08-01   3.7\n",
      "...                                            ...   ...\n",
      "Unemployment Rate (Seasonally Adjusted) 2013-05-01   7.5\n",
      "Unemployment Rate (Seasonally Adjusted) 2013-04-01   7.6\n",
      "Unemployment Rate (Seasonally Adjusted) 2013-03-01   7.5\n",
      "Unemployment Rate (Seasonally Adjusted) 2013-02-01   7.7\n",
      "Unemployment Rate (Seasonally Adjusted) 2013-01-01   8.0\n",
      "\n",
      "[120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total rows for time series since 2013: {len(bls_series)}\")\n",
    "print(bls_series.dtypes)\n",
    "print(f\"Snapshot of the data extracted: {bls_single_series}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kennysim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
